{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math primer for ML & TensorFlow workshop\n",
    "\n",
    "This notebook is meant to provide some basic mathematical backgrounds for the Python ML & TensorFlow Workshop.  Three topics are covered:   \n",
    "\n",
    "1. Structure in Data\n",
    "2. Basic Concepts in TensorFlow\n",
    "3. Loss Function and Gradient Descent\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Structure in Data\n",
    "\n",
    "Intuitively speaking, structure in data means two properties:\n",
    "* Given some data, one can predict the other data points with some confidence \n",
    "* One can compress the data, i.e., store the same amount of information, with less space\n",
    "\n",
    "For example, consider two arrays:\n",
    "\n",
    "A = (1, 2, 6, 2, 4, 7)\n",
    "\n",
    "B = (1, 2, 1, 2, 1, 2)\n",
    "\n",
    "We might say that A does not have apparent structure, whereas B does.\n",
    "\n",
    "### Entropy\n",
    "\n",
    "There are several ways of characterizing \"structure\" in data.  For example, if elements in A and B are draw from probability distributions, then we can define entropy as:\n",
    "\n",
    "$$ H(X)\\;=\\;- \\sum^N_{i=1} p(x_i) \\; log_2 p(x_i) $$\n",
    "\n",
    "To interpret this definition, consider two simple processes: a coin toss and a dice roll.  In each scenario, the outcomes are equally likely, but the numbers of possible outcomes are 2 and 6.  Therefore (in the unit of bits):\n",
    "\n",
    "$$ H(coin\\;toss)\\;=\\;- \\sum^2_{i=1} {1 \\over 2} \\; log_2 {1 \\over 2} \\;=\\; 1.0 $$\n",
    "$$ H(dice\\;roll)\\;=\\;- \\sum^6_{i=1} {1 \\over 6} \\; log_2 {1 \\over 6} \\;=\\; 2.58 $$\n",
    "\n",
    "So the dice roll process has a higher entropy than coin toss; predicting dice roll outcomes is more difficult, i.e., incurs a larger uncertainty.  Now compare a fair coin toss and a biased coin toss (that, say, returns heads 80% of the time):\n",
    "\n",
    "$$ H(50/50\\;coin\\;toss)\\;=\\;- \\sum^2_{i=1} {1 \\over 2} \\; log_2 {1 \\over 2} \\;=\\; 1.0 $$\n",
    "$$ H(20/80\\;coin\\;toss)\\;=\\;- {1 \\over 5} \\; log_2 {1 \\over 5} - {4 \\over 5} \\; log_2 {4 \\over 5} \\;=\\; 0.72 $$\n",
    "\n",
    "So a biased coin toss has lower entropy; predicting its outcome is easier (i.e., less uncertainty) than a fair coin toss.   \n",
    "\n",
    "<!---\n",
    "#### Exercise\n",
    "To continue with the arrays A and B example above, assume these two arrays are representative of the distributions that generated the elements.  Compute the entropy for the distributions that generated A and B. (Note: in real world one almost never knows the actual distribution of a data-generating process.)\n",
    "--->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic concepts for TensorFlow\n",
    "\n",
    "You might recall from linear algebra that arrays have the following names depending on their dimensionality:\n",
    "\n",
    "* Scalar - an array in 0-D\n",
    "* Vector - an array in 1-D\n",
    "* Matrix - an array in 2-D\n",
    "\n",
    "They are all **tensors** of n-th order.  That is, a tensor is an array with arbitrary dimensionality.  Just like how scalars, vectors, and matrices can undergo mathematical operations such as addition and multiplication, tensors can be transformed with operations as well, provided that the input tensors have compatible shapes (for example, you can only add vectors with same number of elements, and multiply an NxM matrix with one that's MxP).  \n",
    "\n",
    "TensorFlow provides a library of algorithms to perform tensor operations efficiently, which are fundemental calculation tasks in machine learning.  For example, consider a simple linear regression model with a single feature:     \n",
    "\n",
    "$$ w_0 + w_1 x \\;=\\; \\hat{y} $$\n",
    "\n",
    "where standard notations are used: $x$ is the feature, $w_0$ and $w_1$ are the **weights** (or parameters) determined during model training, and $\\hat{y}$ is the predicted outcome, to be compared with actual observations $y$.  The goal of building a model is to find values of $w_0$ and $w_1$ that minimize prediction error (but also balanced by the model being generalizable, i.e., not over-fit).  \n",
    "\n",
    "### Graph representation of ML models\n",
    "\n",
    "We can represent linear regression as a **graph**, where data flow from one node to another to undergo mathematical operations.  In this representation, we have\n",
    "\n",
    "<img src=\"./linear_reg_graph.png\" width=\"20%\" height=\"20%\">\n",
    "\n",
    "\n",
    "Consider a slightly larger neural net graph:\n",
    "\n",
    "<img src=\"./nnet_graph.png\" width=\"30%\" height=\"30%\">\n",
    "\n",
    "In this graph, there are three features $x_1$, $x_2$, and $x_3$, which are fed into **activation functions** $a_1^{(2)}$,  $a_2^{(2)}$, and $a_3^{(2)}$ in the second layer (the superscript denotes layer number and the subscript denotes the node number in that layer; note the number of nodes in each layer does not have to be the same as the number of features).  Not shown here are the weights $w$'s similar to the case of linear regression example above.  We can have different weights for different features, as well as for different activation functions.  Therefore, for each activation function $a_i^{(2)}$ in the second layer:\n",
    "\n",
    "$$ a_i^{(2)} \\;\\; = g( w_{i1} x_1 + w_{i2} x_2 + w_{i3} x_3 ),$$\n",
    "\n",
    "where $g(...)$ simply states that the activation function $a_i^{(2)}$ takes the input $w_{i1} x_1 + w_{i2} x_2 + w_{i3} x_3$.  In the simple linear regression example, we have the intercept term $w_0$; we can similarly implement it here in a neural net by adding $w_{i0}$, which is called a **biasing term**:\n",
    "\n",
    "$$ a_i^{(2)} \\; =\\;g( w_{i0} + w_{i1} x_1 + w_{i2} x_2 + w_{i3} x_3 ).$$\n",
    "\n",
    "After the operations at the second layer, the data is subsequently sent to a third layer, with activation functions $a_i^{(3)}$.  One can add nodes and layers to the neural net model; a **deep neural net** is one with many layers, perhaps 10's or 100's.  As you build more complex models using TensorFlow, it could be helpful to visualize your graph.  **[TensorBoard](https://www.tensorflow.org/versions/r0.7/how_tos/graph_viz/index.html)** provides this visualization tool.\n",
    "\n",
    "### Activation functions\n",
    "\n",
    "The activation functions can be different operations.  For example, if $g(...)$ is linear, then we return to linear regression.  So in practice $g(...)$ is typically non-linear, and a popular activation function is the rectified linear unit (**ReLU**):\n",
    "\n",
    "$$g(u)\\;=\\;max(0, u).$$\n",
    "\n",
    "\n",
    "\n",
    "### Model output\n",
    "\n",
    "After the data are pass through layers of operations, the output is generated.  The range of the output value depends on what activation function is used, but generally could be any real number $[-\\infty, +\\infty]$.  For categorical prediction, such as a binary classification of either 0 or 1, an additional sigmoid function can be applied to bring the final output within the range of $[0, 1]$, much like the case of logistic regression:\n",
    "\n",
    "$$ \\sigma(u) \\;=\\; { 1 \\over 1 + e^{-u} }.$$\n",
    "\n",
    "The empty node in the neural net graph above is meant to represent this last operation.  Often we need to make a multi-class prediction, for example, given an image, if the subject is cat, dog, human, car, etc.  In this case we need to transform the output from $[-\\infty, +\\infty]$ to one of the several categories, and a **softmax function** would be used:\n",
    "\n",
    "$$ S_j(\\textbf{u}) \\;=\\; { e^{u_j} \\over \\sum_{k=1}^K e^{u_k} },\\;\\;\\;\\;\\;j\\;\\in\\;[1, 2,... K].$$\n",
    "\n",
    "Here $\\textbf{u}$ is an array with $K$ elements ($u_1$, $u_2$, ... $u_K$), and the function $S$ transforms $\\textbf{u} \\in \\mathbb{R}^K$ to $[0, 1]^K$, while also observing the normalization condition\n",
    "\n",
    "$$ \\sum_{j=1}^K S_j(\\textbf{u})\\;=\\;1.$$\n",
    "\n",
    "In the case of multi-class prediction, each possible state is represented typically with **one-hot encoding** (also known as **dummy encoding** or **one-of-K**).  For example, with coin flip, $K$ = 2 and the two states would be (1,0) and (0,1); for dice roll, $K$ = 6 and the six states would be (1,0,0,0,0,0), (0,1,0,0,0,0), (0,0,1,0,0,0), etc.\n",
    "\n",
    "<!---\n",
    "#### Exercise\n",
    "Show that the softmax function for $K$ = 1 is equivalent to a sigmoid function.\n",
    "--->\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loss functions and gradient descent\n",
    "\n",
    "In a machine learning model, we have input features $\\textbf{x}$, weights $w_i$ (number of weights depends on model), and we make predictions on outcome $y$ which is denoted as $\\hat{y}$.  Good models make good predictions, that is, the difference between predicted $\\hat{y}$ and the actual observations $y$ should be small (without loss of model generalizability, that is, without overfitting).   \n",
    "\n",
    "### Linear regression example\n",
    "\n",
    "For the case of linear regression, we have two weights: $w_0$ and $w_1$, and we want the model to figure out what are good weights by minimizing prediction error, for example, an L2 loss of \n",
    "\n",
    "$$ L\\;=\\;\\sum (y - \\hat{y}) ^ 2,$$\n",
    "\n",
    "which is also known as squared errors (**loss function** is also known as **cost function**; summation is performed over all observation vs prediction pairs).  For linear regression, we can simply replace $\\hat{y}$ with $w_0 + w_1 x$ and get\n",
    "\n",
    "$$ L\\;=\\; L(w_0, w_1)\\;=\\;\\sum (y - w_0 + w_1 x) ^ 2.$$\n",
    "\n",
    "We then want to find $w_0$ and $w_1$ that minimize $L$.  A recipe is to start with some values for $w_0$ and $w_1$, change them a little bit in a way that decreases $L(w_0, w_1)$, and continue until $L(w_0, w_1)$ cannot be reduced further with any new choices of $w_0$ and $w_1$.  More formally, we are doing\n",
    "\n",
    "$$ w^{new}_0 \\;=\\;w^{old}_0 - \\alpha {\\partial \\over \\partial w_0} L(w_0, w_1),$$\n",
    "$$ w^{new}_1 \\;=\\;w^{old}_1 - \\alpha {\\partial \\over \\partial w_1} L(w_0, w_1).$$\n",
    "\n",
    "The parameter $\\alpha$ is the **learning rate**; large $\\alpha$ means each new update of $w_0$ and $w_1$ takes a bigger leap in the direction that reduces $L(w_0, w_1)$, so it should be faster to find optimal $w_0$ and $w_1$ as less number of iterations would be needed.  However, bigger steps also mean that one could miss out on the optimal $w_0$ and $w_1$ by continuously stepping around it.  In terms of implementation, it is feasible to start with larger steps, or a faster learning rate, and then take smaller steps as the model training is approaching the miminum loss function.  This iterative process of updating weights and decreasing loss function is **gradient descent**, and is a key component to machine learning algorithms. \n",
    "\n",
    "### Another loss function\n",
    "\n",
    "Choosing a good loss function is very important in machine learning; the squared error might not be the appropriate choice in all occasions.  For example, consider a logistic regression model where predictions $\\hat{y}$ are computed via a sigmoid function\n",
    "\n",
    "$$ \\hat{y} \\;=\\; { 1 \\over 1 + e^{ w_0 + w_1 x} }.$$\n",
    "\n",
    "The resulting $\\hat{y}$ is between 0 and 1, and carries a probabilistic interpretation\n",
    "\n",
    "$$ \\hat{p}\\,(y = 1) \\;=\\; \\hat{y}, $$\n",
    "$$ \\hat{p}\\,(y = 0) \\;=\\; 1 - \\hat{y}.$$\n",
    "\n",
    "Instead of comparing $\\hat{y}$ with actual observations $y$, in the case of logistic regression the quality of predictions is determined by $\\hat{p}\\,(y = 1)$, which we want to compare with the observed probability $p\\,(y = 1)$.  One way of comparing two probability distributions is **cross entropy**\n",
    "\n",
    "$$ H(p, \\hat{p}) \\;=\\; \\sum_i \\, p_i \\, log(\\hat{p_i}) \\;=\\; -y \\, log(\\hat{y})\\,-\\,(1-y)\\,log(1-\\hat{y}). $$\n",
    "\n",
    "Note, cross entropy is not symmetric, and that if $p$ = $\\hat{p}$, we simply get back the entropy of $p$.  As $\\hat{p}$ deviates from $p$, $H(p, \\hat{p})$ increases, so a good error function for logistic regression is cross entropy, which one would minimize as the error function.  This is also known as the **log loss**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
